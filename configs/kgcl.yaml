
# recbole/properties/overall.yaml


# from SSLRec
# optimizer:
#   name: adam
#   lr: 1.0e-3 # not 1e-3
#   weight_decay: 0

# train:
#   trainer: kgcl_trainer
#   epoch: 100
#   batch_size: 1024
#   kg_batch_size: 4096
#   save_model: true
#   loss: pairwise # bpr
#   test_step: 1 # evaluate per {test_step} epochs
#   #pretrain_path: ./checkpoint/xxxx.pth
#   reproducible: true
#   seed: 2020

# test:
#   metrics: [recall, ndcg] # choose in {ndcg, recall, precision, mrr}
#   k: [10, 20, 40] # top-k
#   batch_size: 1024 # How many users per batch during validation
#   eval_at_one_forward: true

# data:
#   type: kg # choose in {general_cf, multi_behavior, sequential, social, kg}
#   # name: last-fm
#   name: lfm-small

# model:
#   name: kgcl # case-insensitive
#   train_trans: false
#   layer_num: 2
#   layer_num_kg: 2
#   decay_weight: 1.0e-5
#   embedding_size: 64
#   node_dropout: true
#   node_dropout_rate: 0.5
#   mess_dropout: true
#   mess_dropout_rate: 0.1

#   tau: 0.2
#   cl_weight: 0.1
#   mu: 0.7

# tune:
#   enable: false # Whether to enable grid search to search for optimal hyperparameters
#   hyperparameters: [layer_num] # The name of the hyperparameter
#   layer_num: [1, 2, 3] # Use a list to store the search range


# dataset config : Knowledge-based Recommendation
USER_ID_FIELD: user_id
ITEM_ID_FIELD: item_id
HEAD_ENTITY_ID_FIELD: head_id
TAIL_ENTITY_ID_FIELD: tail_id
RELATION_ID_FIELD: relation_id
ENTITY_ID_FIELD: entity_id
load_col:
    inter: [user_id, item_id]
    kg: [head_id, relation_id, tail_id]
    link: [item_id, entity_id]
# benchmark_filename: ['train', 'valid', 'test']

# model config
embedding_size: 64
kg_embedding_size: 64
reg_weights: [1e-02,1e-02]

# Training and evaluation config
epochs: 100 #训练的最大轮数
train_batch_size: 1024 #训练的batch_size
eval_batch_size: 4096
learner: adam     #使用的pytorch内置优化器
learning_rate: 0.001 #学习率
# training_neg_sample_num: 1 #负采样数目
eval_step: 1      #每次训练后做evalaution的次数
stopping_step: 30 #控制训练收敛的步骤数，在该步骤数内若选取的评测标准没有什么变化，就可以提前停止了

# eval_setting: RO_RS,full #对数据随机重排，按比例划分数据集，并使用全排序
eval_args:
   split: {'RS': [0.8, 0.1, 0.1]}
   group_by: user
   order: RO
   mode: full
metrics: ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']
topk: [20]
valid_metric: Recall@20

# envronment
# gpu_id: 0
# log_wandb: True



# quck_start_config/knowledge_base.yaml
# Data preprocessing for knowledge graph triples
kg_reverse_r: False                     # (bool) Whether to reverse relations of triples for bidirectional edges.
entity_kg_num_interval: "[0,inf)"       # (str) Entity interval for filtering kg.
relation_kg_num_interval: "[0,inf)"     # (str) Relation interval for filtering kg.


# model: Ours
# # 默认值为
# embedding_size: 64              # (int) The embedding size of users, items, entities and relations.
# reg_weight: 1e-5                # (float) The L2 regularization weight.
# node_dropout_rate: 0.5          # (float) The node dropout rate in GCN layer.
# mess_dropout_rate: 0.0          # (float) The message dropout rate in GCN layer.
# sim_regularity: 1e-4            # (float) The intents independence loss weight.
# context_hops: 2                 # (int) The number of context hops in GCN layer.
# n_factors: 4                    # (int) The number of user intents.
# ind: 'cosine'                   # (float) The intents independence loss type. # distance, cosine
# temperature: 0.2                # (float) The temperature parameter used in loss calculation.

train_trans: false
layer_num: 2
layer_num_kg: 2
decay_weight: 1.0e-5
embedding_size: 64
node_dropout: true
node_dropout_rate: 0.5
mess_dropout: true
mess_dropout_rate: 0.1

devide: cuda

# ===== DATA
data_path: dataset/
# dataset: ml-1m
# save_dataset: True
# dataset_save_path: 

# =========== DIR
checkpoint_dir: saved/
